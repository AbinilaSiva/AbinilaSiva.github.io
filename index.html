<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Portfolio Website" />
    <meta name="author" content="Abinila Siva" />
    <meta
      name="keywords"
      content="Abinila Siva, Abinila, Abi Siva, Abinila S, Abinila SIVA UCR, Abinila Siva .ai, abinilasiva , Siva"
    />

    <link rel="shortcut icon" href="./assets/img/ai.jpg" />
    <title>Abinila Siva</title>

    <link rel="stylesheet" href="./assets/css/main.css" />
  </head>

  <body>
    <div id="particles-js">
      <div class="header">
        <h1>
          <span class="site-title">Abinila Siva</span>
          <span class="site-description">AI Engineer</span>
        </h1>
        <div class="header-icons">
          <a
            aria-label="My LinkedIn Profile"
            target="_blank"
            href="https://www.linkedin.com/in/abinila-siva/"
          >
            <i class="icon fab fa-linkedin" aria-hidden="true"></i>
          </a>
          <a
            aria-label="My Github Profile"
            target="_blank"
            href="https://github.com/AbinilaSiva"
          >
            <i class="icon fab fa-github" aria-hidden="true"></i>
          </a>
          <a
            aria-label="My Résumé"
            target="_blank"
            href="https://drive.google.com/file/d/1BLBndQcUzYNGAACaJ6ljnV_0p20lKpXK/view?usp=sharing"
          >
            <i class="icon fas fa-file-pdf" aria-hidden="true"></i>
          </a>
          <a
            aria-label="Send Email"
            href="mailto:asiva017@ucr.edu"
            target="_blank"
            ><i class="icon fa fa-envelope"></i
          ></a>
        </div>
        <div class="header-links">
          <a class="link" href="#about" data-scroll>About Me</a>
          <a class="link" href="#work-experience" data-scroll>Work Experience</a> 
          <a class="link" href="#projects" data-scroll>Projects</a>
        </div>
      </div>
      <a class="down" href="#about" data-scroll
        ><i class="icon fa fa-chevron-down" aria-hidden="true"></i
      ></a>
    </div>
    <section id="about">
      <div class="avatar" align="center">
        <img src="assets/img/abi.jpg" alt="Avatar" align="center"/>
      </div>

      <div class="user-details">
        <h3>
          Welcome to My Professional Space
        </h3>
        <p>
          I'm an AI/ML Engineer with a Master of Science in Computer Science from University of California, Riverside. Specializing in Artificial Intelligence, Machine Learning, Computer Vision, and Generative AI, I have honed my skills in deep learning and cutting-edge technologies to create innovative solutions with significant impact. My academic and professional journey is marked by a commitment to excellence and a passion for transforming complex challenges into transformative advancements. Let's explore how we can drive technological breakthroughs together.
        </p>
        <h3>
          Professional Odyssey and Expertise:
        </h3>
        <p>
          My career began at Multicoreware Inc, where I navigated the complexities of AI, from optimizing deep learning algorithms for efficiency and effectiveness to deploying advanced models on embedded platforms. My work has significantly contributed to autonomous vehicle technologies, highlighting my expertise in AI quantization, GPU acceleration, and cloud technologies. These experiences have honed my skills in Python, C++, TensorFlow, PyTorch, and cloud services like AWS, alongside DevOps tools such as Docker and Kubernetes.
        </p>
        <h3>
          Looking Forward:
        </h3>
        <p>
          As I carve my path forward, I am keenly interested in opportunities that allow me to leverage my comprehensive background in engineering, my passion for AI, and my proven track record of innovative solution development. I am particularly excited about roles that challenge me to push the boundaries of what's possible with AI/ML and Computer Vision, contributing to transformative projects that not only solve complex problems but also make a meaningful impact on the industry and society at large.
        </p>
        <p>
          Interested in working together or having a chat? Feel free to drop me a line on <a class="text-link" href = "mailto:asiva017@ucr.edu">email</a> or <a class="text-link" href = "https://www.linkedin.com/in/abinila-siva/">LinkedIn</a>.
        </p>
      </p>
      </div>

    </section>

    <section id="work-experience">
      <h2 class="section-title">Work Experience</h2>
      <div class="experience-block">
        <h3 class="job-title">Software Engineer Intern - Multicoreware Inc, San Jose, CA</h3>
        <p class="job-duration">June 2023 - Dec 2023</p>
        <p class="job-description">
          At the cutting edge of autonomous vehicle technology, I embarked on an exhilarating journey with Multicoreware Inc in San Jose. My tenure as a Software Engineer Intern was marked by a pioneering comparative study of 3D object detection algorithms - VoxelNet, PointPillar, and Center-Point, all meticulously integrated with Camera-Lidar and Camera-Sensor fusion. This endeavor utilized Amazon SageMaker, which was instrumental in the development and training of these models. The highlight of my internship was the creation of a groundbreaking hybrid AI system for Autonomous Trucking. This system, a blend of Deep Neural Networks (DNN) and geometric techniques, excelled in accurate lane marking and center estimation through a Forward Facing Camera. The experience was not just a job; it was a venture into the future of mobility, driving my passion for innovation in autonomous systems.
        </p>
      </div>
    
      <div class="experience-block">
        <h3 class="job-title">Software Engineer - Multicoreware Inc, Chennai, India</h3>
        <p class="job-duration">Dec 2020 - June 2022</p>
        <p class="job-description">
          My professional journey began in Chennai, India, where I joined Multicoreware Inc as a Software Engineer. It was here that I delved into the intricacies of AI model optimization, enhancing over 20 algorithms across a spectrum of model types including Image Classification, Object Detection, Semantic Segmentation, and Transformer models. Utilizing Qualcomm's AIMET SDK, I achieved remarkable precision with less than 2% loss in accuracy during INT8 quantization. This was a pivotal achievement in AI Quantization, crucial for 8-bit acceleration and Edge deployment.

          The deployment of quantized ONNX models on Nvidia-Jetson Xavier and Qualcomm (QNNDrive) hardware was a testament to our relentless pursuit of excellence. Leveraging ONNX Runtime and TensorRT, I conducted exhaustive benchmarking and performance evaluations. The results were astounding - up to a 25% improvement in accuracy and model integrity during quantization, thanks to a meticulous layer-by-layer analysis.

          This role was not just about technical achievements; it was about making a tangible impact on the safety and precision of ADAS applications, underscored by an unwavering focus on GPU enhancements. My contributions were recognized with the "Spot Award" in 2021-2022, a moment of great pride and a testament to my dedication to advancing autonomous driving technology.

          Throughout this journey, my technical arsenal expanded to include C++, Python, PyTorch, TensorFlow, and a mastery in GPU parallelism, alongside an in-depth understanding of ONNX. Each step of the process, from setting up a baseline and ensuring FP32 accuracy to quantization with AIMET and detailed performance analysis, fueled my passion for the field.

          This journey has been more than a job; it's been a passionate quest for innovation, driving forward the boundaries of what's possible in AI and autonomous systems. My experience at Multicoreware Inc has been a cornerstone of my professional development, laying a solid foundation for future endeavors in this exciting and dynamic field.
        </p>
      </div>
    </section>

    <section id="projects">
      <div class="user-details">
        <h1> Personal Projects </h1>
      </div>
      
      <div class="user-projects">
        <div class="images-left">
            <img alt="AI-Driven Financial Analysis Chatbot" src="./assets/img/giphy.gif" />
        </div>
        <div class="contents-right">
            <h3>AI-Driven Financial Analysis Chatbot</h3>
            
            <h4>Project Overview:</h4>
            <p>Engineered an advanced AI-driven chatbot for real-time financial market analysis, leveraging two cutting-edge models: GPT-3.5 integrated with Yahoo Finance API for data-driven insights, and LLaMA-2 combined with Retrieval-Augmented Generation (RAG) for dynamic finance-related Q&A. The project features web scraping with BeautifulSoup and Selenium, offering users accurate market outlooks through a user-friendly GUI on Streamlit for one version, and a sophisticated Q&A interface in the other.</p>
            
            <h4>Key Features:</h4>
            <ul>
                <li><strong>Dual-Model Integration:</strong> Offers two versions employing GPT-3.5 and LLaMA-2 models for diverse user queries.</li>
                <li><strong>Real-Time Data Acquisition:</strong> Utilized BeautifulSoup and Selenium for efficient web scraping, ensuring access to the latest financial information.</li>
                <li><strong>User-Friendly Interface:</strong> Streamlit-based interface enhances user experience with easy navigation and interaction.</li>
            </ul>
            
            <h4>Technologies Used:</h4>
            <p>Python, BeautifulSoup, Selenium, GPT-3.5, LLaMA-2, RAG, Yahoo Finance API, Streamlit.</p>
            
            <p align="center">
                <a class="project-link" href="https://github.com/AbinilaSiva/AI-Driven-Financial-Chatbot">Source</a>
            </p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <img alt="2D Object Detection on RADAR Dataset Visualization" src="./assets/img/radar.gif" />
        </div>
        <div class="contents-left">
            <h3>2D Object Detection on RADAR Dataset in Adverse Weather</h3>
            <p>
              Enhancing autonomous vehicle navigation, this initiative implemented Faster R-CNN with ResNet 101 for 2D radar-based object detection under challenging weather. Using the RADIATE dataset, it showcased a significant improvement in detection precision, reinforcing radar's advantage over cameras in poor visibility conditions.
            </p>
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Faster R-CNN and ResNet 101:</strong> Utilized for robust 2D object detection, highlighting the effectiveness of radar over camera sensors in adverse conditions.</li>
                <li><strong>RADIATE Dataset:</strong> Empowered the research with extensive radar sensor data, facilitating a comprehensive analysis of object detection performance in various weather scenarios.</li>
                <li><strong>Precision Improvement:</strong> Achieved a 35% increase in object detection precision, setting new benchmarks for accuracy in autonomous vehicle sensing technologies.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>Faster R-CNN, ResNet 101, RADIATE dataset, Radar Sensor Technology, Python.</p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <img alt="Emotion Detection from Tom and Jerry videos gif" src="./assets/img/emotion-detection-480.gif" />
        </div>
        <div class="contents-left">
            <h3>Emotion Detection from Tom and Jerry Videos</h3>
            <p>
                This project marries machine learning with computer vision to create an emotion detection system for "Tom and Jerry" animations. A custom dataset was developed by labeling video frames for emotions like Happy, Angry, Sad, and Surprised using the LabelImg tool. The system employs the YOLO algorithm for object detection and VGG-19 CNN for classifying emotions, achieving a notable 82.9% accuracy in recognizing emotional expressions.
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Dataset Construction:</strong> Leveraged the LabelImg tool for detailed annotation, creating a custom dataset from "Tom and Jerry" video frames.</li>
                <li><strong>Object Detection:</strong> Implemented the YOLO (You Only Look Once) algorithm for pinpointing emotions in real-time.</li>
                <li><strong>Emotion Classification:</strong> Utilized the VGG-19 Convolutional Neural Network for distinguishing complex emotions with high accuracy.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>Python, OpenCV, YOLO, VGG-19 CNN, LabelImg.</p>
            <p align="center">
                <a class="project-link" href="https://github.com/AbinilaSiva/Cartoon-Emotion-Detection">Source</a>
            </p>
        </div>
      </div>
      
      <div class="user-projects">
        <div class="images-left">
            <img alt="FLAN-T5 Dialogue Summarization gif" src="./assets/img/giphy_summerization.gif" />
        </div>
        <div class="contents-right">
            <h3>Enhanced & Detoxified Dialogue Summarization with FLAN-T5</h3>
            <p>
                This project elevates dialogue summarization by utilizing FLAN-T5 for a spectrum of inferences and prompt engineering, bolstered by PEFT fine-tuning and PPO for content detoxification. It delivers summaries with unparalleled accuracy and ethical alignment.
            </p>
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Advanced Summarization Techniques:</strong> Employed FLAN-T5 with zero, one, and many-shot inferences for versatile learning capabilities.</li>
                <li><strong>PEFT Fine-Tuning:</strong> Conducted precise model tuning with Prompt Engineering with Fine-Tuned templates to optimize summarization performance.</li>
                <li><strong>Detoxification via PPO:</strong> Applied Proximal Policy Optimization to effectively reduce toxic content, ensuring integrity in generated text.</li>
            </ul>
            <h4>Outcomes:</h4>
            <p> The initiative resulted in notable improvements in summarization precision, as evidenced by ROUGE metric evaluations, enhancing both accuracy and content quality.
            </p>
            <h4>Technologies Used:</h4>
            <p>FLAN-T5, Proximal Policy Optimization (PPO), ROUGE metrics, Python.</p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <img alt="Anime Recommendation System Visualization" src="./assets/img/anime_gif.gif" />
        </div>
        <div class="contents-left">
            <h3>Anime Recommendation System</h3>
            <p>
                Engineered a robust Anime Recommendation System using PySpark's ALS for collaborative filtering, capable of handling a 7.35GB dataset to refine user personalization and accuracy. The system features a PySpark-driven backend with Flask API integration and a React frontend for an immersive user experience.
             </p>
            <h4>Key Features:</h4>
            <ul>
                <li><strong>Scalable Architecture:</strong> Efficient data management with PySpark ensures adaptability to large datasets.</li>
                <li><strong>Personalized Recommendations:</strong> ALS matrix factorization fine-tunes user-specific suggestions.</li>
                <li><strong>Full-Stack Interface:</strong> A synergistic backend and frontend development with Flask and React create a seamless platform.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>PySpark, ALS Matrix Factorization, Flask, React, Collaborative Filtering.</p>
        </div>
      </div>
  
      <div class="user-projects">
        <div class="images-left">
            <img alt="Geospatial Wildfire Risk Prediction Visualization" src="./assets/img/wildfire.gif" />
        </div>
        <div class="contents-right">
            <h3>Geospatial Wildfire Risk Prediction</h3>
            <p>
              This project pioneers a machine learning system using U-Net to predict wildfires from satellite data with high precision. Analyzing indices like NDVI and LST from MODIS, and integrating with ArcGIS for detailed visualizations, it substantially aids in early detection and disaster readiness.
            </p>
            <h4>Highlights:</h4>
            <ul>
                <li><strong>U-Net for Spatial Data:</strong> Precision segmentation to assess wildfire risks.</li>
                <li><strong>Geospatial Data Analysis:</strong> Utilized ArcGIS for sophisticated visualization and in-depth analysis of geospatial data related to wildfire risks.</li>
                <li><strong>Comprehensive Risk Assessment:</strong> Integrated various data points (NDVI, LST, thermal anomalies) for a holistic view of potential wildfire hazards.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>U-Net Model, MODIS Satellite Data, ArcGIS, Python, Machine Learning, Geospatial Analysis.</p>
        </div>
      </div>

    
      </div>
      
    </section>

    <footer class="footer" style="margin-left: 0px;">
      <p>&copy; Abinila Siva, 2023</p>
      <p>Built with Jekyll and the <a href="https://github.com/nrandecker/particle">particle</a> template by <a href="https://github.com/nrandecker">Nathan Randecker</a></p>
    </footer>

    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script src="./assets/js/sweet-scroll.min.js"></script>
    <script src="./assets/js/google-analytics.js"></script>
    <script src="./assets/js/main.js"></script>
  </body>
</html>
