<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Portfolio Website" />
    <meta name="author" content="Abinila Siva" />
    <meta
      name="keywords"
      content="Abinila Siva, Abinila, Abi Siva, Abinila S, Abinila SIVA UCR, Abinila Siva .ai, abinilasiva , Siva"
    />

    <link rel="shortcut icon" href="./assets/img/favicon.jpeg" />
    <title>Abinila Siva</title>

    <link rel="stylesheet" href="./assets/css/main.css" />
  </head>

  <body>
    <div id="particles-js">
      <div class="header">
        <h1>
          <span class="site-title">Abinila Siva</span>
          <span class="site-description">AI Engineer</span>
        </h1>
        <div class="header-icons">
          <a
            aria-label="My LinkedIn Profile"
            target="_blank"
            href="https://www.linkedin.com/in/abinila-siva/"
          >
            <i class="icon fab fa-linkedin" aria-hidden="true"></i>
          </a>
          <a
            aria-label="My Github Profile"
            target="_blank"
            href="https://github.com/AbinilaSiva"
          >
            <i class="icon fab fa-github" aria-hidden="true"></i>
          </a>
          <a
            aria-label="My Résumé"
            target="_blank"
            href="https://drive.google.com/file/d/1BLBndQcUzYNGAACaJ6ljnV_0p20lKpXK/view?usp=sharing"
          >
            <i class="icon fas fa-file-pdf" aria-hidden="true"></i>
          </a>
          <a
            aria-label="Send Email"
            href="mailto:asiva017@ucr.edu"
            target="_blank"
            ><i class="icon fa fa-envelope"></i
          ></a>
        </div>
        <div class="header-links">
          <a class="link" href="#about" data-scroll>About Me</a>
          <a class="link" href="#projects" data-scroll>Projects</a>
        </div>
      </div>
      <a class="down" href="#about" data-scroll
        ><i class="icon fa fa-chevron-down" aria-hidden="true"></i
      ></a>
    </div>
    <section id="about">
      <div class="avatar" align="center">
        <img src="assets/img/abi.jpg" alt="Avatar" align="center"/>
      </div>

      <div class="user-details">
        <h3>
          Welcome to My Professional Space
        </h3>
        <p>
          I'm an AI/ML Engineer with a Master of Science in Computer Science from University of California, Riverside. Specializing in Artificial Intelligence, Machine Learning, Computer Vision, and Generative AI, I have honed my skills in deep learning and cutting-edge technologies to create innovative solutions with significant impact. My academic and professional journey is marked by a commitment to excellence and a passion for transforming complex challenges into transformative advancements. Let's explore how we can drive technological breakthroughs together.
        </p>
        <h3>
          Professional Odyssey and Expertise:
        </h3>
        <p>
          My career began at Multicoreware Inc, where I navigated the complexities of AI, from optimizing deep learning algorithms for efficiency and effectiveness to deploying advanced models on embedded platforms. My work has significantly contributed to autonomous vehicle technologies, highlighting my expertise in AI quantization, GPU acceleration, and cloud technologies. These experiences have honed my skills in Python, C++, TensorFlow, PyTorch, and cloud services like AWS, alongside DevOps tools such as Docker and Kubernetes.
        </p>
        <h3>
          Educational Foundation:
        </h3>
        <p>
          Armed with a Bachelor of Engineering in Computer Science and Engineering from Kumaraguru College,Anna University, I furthered my education with a Master's from UC Riverside, achieving a GPA of 3.69. My academic projects span a wide range, from AI-driven financial analysis chatbots to emotion detection in videos and geospatial wildfire risk prediction, each underscoring my ability to apply theoretical knowledge to real-world problems.
        </p>
        <h3>
          Looking Forward:
        </h3>
        <p>
          As I carve my path forward, I am keenly interested in opportunities that allow me to leverage my comprehensive background in engineering, my passion for AI, and my proven track record of innovative solution development. I am particularly excited about roles that challenge me to push the boundaries of what's possible with AI/ML and Computer Vision, contributing to transformative projects that not only solve complex problems but also make a meaningful impact on the industry and society at large.
        </p>
        <p>
          Interested in working together or having a chat? Feel free to drop me a line on <a class="text-link" href = "mailto:asiva017@ucr.edu">email</a> or <a class="text-link" href = "https://www.linkedin.com/in/abinila-siva/">LinkedIn</a>.
        </p>
      </p>
      </div>

    </section>
    <section id="projects">
      <div class="user-details">
        <h1> Personal Projects </h1>
      </div>
      
      <div class="user-projects">
        <div class="images-left">
            <img alt="AI-Driven Financial Analysis Chatbot" src="./assets/img/giphy.gif" />
        </div>
        <div class="contents-right">
            <h3>AI-Driven Financial Analysis Chatbot</h3>
            <p>An advanced GUI-based chatbot for real-time financial market insights, utilizing web scraping with BeautifulSoup and Selenium, and AI models including GPT-3.5 with Yahoo Finance API, and LLaMA-2 with RAG for finance-related Q&A.</p>
            
            <h4>Project Overview:</h4>
            <p>This project showcases an advanced, GUI-based chatbot designed to provide users with real-time financial market insights. Leveraging the power of web scraping and AI, the chatbot offers a dynamic interface for querying up-to-the-minute financial data and market outlooks.</p>
            
            <h4>Key Features:</h4>
            <ul>
                <li><strong>Dual-Model Integration:</strong> Developed two distinct versions to cater to diverse user needs. The first integrates OpenAI's GPT-3.5 with the Yahoo Finance API for comprehensive market analysis, while the second employs Meta's LLaMA-2 models alongside the RAG (Retrieval-Augmented Generation) technique, enabling detailed finance-related Q&A with direct source citations.</li>
                <li><strong>Real-Time Data Acquisition:</strong> Utilized BeautifulSoup and Selenium for efficient web scraping, ensuring access to the latest financial information.</li>
                <li><strong>User-Friendly Interface:</strong> Deployed on Streamlit, offering an intuitive, interactive user experience that makes financial analysis accessible to both novices and experts.</li>
            </ul>
            
            <h4>Technologies Used:</h4>
            <p>Python, BeautifulSoup, Selenium, GPT-3.5, LLaMA-2, RAG, Yahoo Finance API, Streamlit.</p>
            
            <p align="center">
                <a class="project-link" href="https://github.com/AbinilaSiva/AI-Driven-Financial-Chatbot">Source</a>
            </p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <img alt="Emotion Detection from Tom and Jerry videos gif" src="./assets/img/emotion-detection-480.gif" />
        </div>
        <div class="contents-left">
            <h3>Emotion Detection from Tom and Jerry Videos</h3>
            <p>
                Diving into the intersection of machine learning and computer vision, this project pioneered the development of an emotion detection system tailored for the dynamic and expressive world of "Tom and Jerry" animations. By meticulously extracting and labeling video frames from YouTube clips, we crafted a specialized dataset to identify and classify four fundamental emotions: Happy, Angry, Sad, and Surprised.
            </p>
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Dataset Construction:</strong> Leveraged the LabelImg tool for detailed annotation, creating a custom dataset from "Tom and Jerry" video frames.</li>
                <li><strong>Object Detection:</strong> Implemented the YOLO (You Only Look Once) algorithm for robust and real-time object detection within the animated frames.</li>
                <li><strong>Emotion Classification:</strong> Utilized the VGG-19 Convolutional Neural Network model for accurate emotion classification, showcasing the deep learning model's capability to discern complex emotional states.</li>
            </ul>
            <h4>Achievements:</h4>
            <p>
                The project achieved an impressive 82.9% accuracy rate in emotion detection, underscoring the effectiveness of combining advanced object detection and CNN models for emotion classification in animated content.
            </p>
            <h4>Technologies Used:</h4>
            <p>Python, OpenCV, YOLO, VGG-19 CNN, LabelImg.</p>
            <p align="center">
                <a class="project-link" href="https://github.com/AbinilaSiva/Cartoon-Emotion-Detection">Source</a>
            </p>
        </div>
      </div>
      
      <div class="user-projects">
        <div class="images-right">
            <!-- Replace with an appropriate image/gif for your FLAN-T5 project -->
            <img alt="FLAN-T5 Dialogue Summarization gif" src="./assets/img/giphy_summerization.gif" />
        </div>
        <div class="contents-left">
            <h3>Enhanced & Detoxified Dialogue Summarization with FLAN-T5</h3>
            <p>
                Leveraging the cutting-edge FLAN-T5 model, this project introduces a novel approach to dialogue summarization, incorporating zero, one, and many-shot inferences, along with prompt engineering, to significantly enhance summary quality. Through the strategic use of full and PEFT fine-tuning, alongside Proximal Policy Optimization (PPO) for content detoxification, it sets new standards for generating accurate and ethically aligned text summaries.
            </p>
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Advanced Summarization Techniques:</strong> Employed FLAN-T5 with zero, one, and many-shot inferences for versatile learning capabilities.</li>
                <li><strong>PEFT Fine-Tuning:</strong> Conducted precise model tuning with Prompt Engineering with Fine-Tuned templates to optimize summarization performance.</li>
                <li><strong>Detoxification via PPO:</strong> Applied Proximal Policy Optimization to effectively reduce toxic content, ensuring integrity in generated text.</li>
            </ul>
            <h4>Achievements:</h4>
            <p>
                The project culminated in achieving significant enhancements in dialogue summarization, validated through ROUGE metrics, demonstrating a marked improvement in accuracy and content safety.
            </p>
            <h4>Technologies Used:</h4>
            <p>FLAN-T5, Proximal Policy Optimization (PPO), ROUGE metrics, Python.</p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <!-- Replace with an appropriate image/gif for your Anime Recommendation System project -->
            <img alt="Anime Recommendation System Visualization" src="./assets/img/anime_gif.gif" />
        </div>
        <div class="contents-left">
            <h3>Anime Recommendation System</h3>
            <p>
                Developed a scalable Anime Recommendation System, leveraging the power of PySpark's ALS (Alternating Least Squares) matrix factorization method for collaborative filtering. This system was designed to process a substantial 7.35GB dataset, significantly enhancing user personalization and recommendation accuracy.
            </p>
            <p>
                The backend of the system was engineered with parallel data processing pipelines in PySpark, integrated with Flask to manage API endpoints efficiently. On the frontend, React was utilized to create an engaging and interactive user experience, allowing for seamless navigation and exploration of recommended anime titles.
            </p>
            <h4>Project Highlights:</h4>
            <ul>
                <li><strong>Scalable System Design:</strong> Employed PySpark for efficient handling and processing of large-scale data, ensuring the system's scalability.</li>
                <li><strong>Collaborative Filtering:</strong> Utilized ALS matrix factorization for collaborative filtering, achieving high levels of personalization in recommendations.</li>
                <li><strong>Full Stack Development:</strong> Combined Flask and React to create a robust backend and a dynamic frontend, facilitating a comprehensive and intuitive application.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>PySpark, ALS Matrix Factorization, Flask, React, Collaborative Filtering.</p>
        </div>
      </div>
  
      <div class="user-projects">
        <div class="images-right">
            <!-- Replace with a relevant image or visualization from your project -->
            <img alt="Geospatial Wildfire Risk Prediction Visualization" src="./assets/img/wildfire.gif" />
        </div>
        <div class="contents-left">
            <h3>Geospatial Wildfire Risk Prediction</h3>
            <p>
                In a groundbreaking effort to enhance wildfire management and prevention strategies, this project introduced a machine learning-based system capable of predicting wildfire dangers with remarkable precision. Utilizing the U-Net convolutional neural network model, the system segments and analyzes satellite spatial data, including Normalized Difference Vegetation Index (NDVI), Land Surface Temperature (LST), and thermal anomalies, sourced from the Moderate Resolution Imaging Spectroradiometer (MODIS) instruments.
            </p>
            <p>
                The project further integrates advanced data visualization and analysis through ArcGIS, offering a comprehensive and detailed representation of wildfire risks. This combination of cutting-edge machine learning techniques and geospatial analysis tools provides invaluable insights for early wildfire detection and risk assessment, contributing significantly to disaster preparedness and environmental protection efforts.
            </p>
            <h4>Key Features:</h4>
            <ul>
                <li><strong>Advanced Machine Learning:</strong> Employed the U-Net Model for precise segmentation of satellite spatial data, enabling effective wildfire risk prediction.</li>
                <li><strong>Geospatial Data Analysis:</strong> Utilized ArcGIS for sophisticated visualization and in-depth analysis of geospatial data related to wildfire risks.</li>
                <li><strong>Comprehensive Risk Assessment:</strong> Integrated various data points (NDVI, LST, thermal anomalies) for a holistic view of potential wildfire hazards.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>U-Net Model, MODIS Satellite Data, ArcGIS, Python, Machine Learning, Geospatial Analysis.</p>
        </div>
      </div>

      <div class="user-projects">
        <div class="images-right">
            <!-- Ensure to replace with a relevant image or visualization from your project -->
            <img alt="2D Object Detection on RADAR Dataset Visualization" src="./assets/img/radar.gif" />
        </div>
        <div class="contents-left">
            <h3>2D Object Detection on RADAR Dataset in Adverse Weather</h3>
            <p>
                From August to October 2023, this project advanced the field of autonomous vehicle navigation by implementing Faster R-CNN with a ResNet 101 backbone for 2D object detection. Focused on the RADIATE dataset, it underscored the utility of radar sensors in adverse weather conditions, significantly enhancing the reliability and safety of autonomous driving technologies in fog, rain, and snow.
            </p>
            <p>
                Demonstrating radar's superiority over traditional camera sensors in extreme weather, the project achieved a 35% increase in precision for object detection. This breakthrough provides a crucial step forward in developing autonomous vehicles that can safely navigate through challenging environmental conditions.
            </p>
            <h4>Technical Highlights:</h4>
            <ul>
                <li><strong>Faster R-CNN and ResNet 101:</strong> Utilized for robust 2D object detection, highlighting the effectiveness of radar over camera sensors in adverse conditions.</li>
                <li><strong>RADIATE Dataset:</strong> Empowered the research with extensive radar sensor data, facilitating a comprehensive analysis of object detection performance in various weather scenarios.</li>
                <li><strong>Precision Improvement:</strong> Achieved a 35% increase in object detection precision, setting new benchmarks for accuracy in autonomous vehicle sensing technologies.</li>
            </ul>
            <h4>Technologies Used:</h4>
            <p>Faster R-CNN, ResNet 101, RADIATE dataset, Radar Sensor Technology, Python.</p>
        </div>
      </div>
    
      </div>
      
    </section>

    <footer class="footer" style="margin-left: 0px;">
      <p>&copy; Abinila Siva, 2023</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script src="./assets/js/sweet-scroll.min.js"></script>
    <script src="./assets/js/google-analytics.js"></script>
    <script src="./assets/js/main.js"></script>
  </body>
</html>
